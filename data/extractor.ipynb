{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51e40f5e-c8c9-49f8-92ac-8f716780fda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "from rasterio.windows import from_bounds\n",
    "from rasterio.features import rasterize\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as geopd\n",
    "\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "plt.rcParams[\"figure.dpi\"]  = 400\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b15622a6-6735-414a-91cd-0e21883deb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to data sources\n",
    "src_path = \"/path/to/filename.gpkg\"\n",
    "\n",
    "\n",
    "land_cover_paths = {2000: \"/path/to/filename.tif\", \n",
    "    2006: \"/path/to/filename.tif\",\n",
    "    2012: \"/path/to/filename.tif\",\n",
    "    2018: \"/path/to/filename.tif\"\n",
    "}\n",
    "\n",
    "lc_classes = {1 : \"crop\", 2 : \"grass\", 3 : \"shrubs\",\n",
    "              4 : \"dwood\", 5: \"ewood\", 6: \"urban\",\n",
    "              7:\"inwater\", 8: \"bares\", 9: \"wetland\"\n",
    "             } # Check that your data source has the same classification\n",
    "# Getting all the land cover column names\n",
    "lc_columns = []\n",
    "for lc_year in land_cover_paths:\n",
    "    lc_columns.extend([f\"{lc_classes[key]}_perc_{lc_year}\" for key in lc_classes.keys()])\n",
    "\n",
    "soil_path = \"/path/to/filename.gpkg\"\n",
    "soil_classes = {\n",
    "    \"bedrock\": [195110, 195111, 195112, 195312],\n",
    "    \"glaciofluvial\": [195310],\n",
    "    \"silt\": [195410],\n",
    "    \"till\": [195210],\n",
    "    \"clay\": [195413, 195511, 195618],\n",
    "    \"peat\": [19551891, 19551892, 19551822]\n",
    "    } # Check that your data source has the same classification\n",
    "soil_columns = [f\"{key}_perc\" for key in soil_classes]\n",
    "\n",
    "soil_depth_path = \"/path/to/filename.tif\"\n",
    "\n",
    "slope_path = \"/path/to/filename.tif\"\n",
    "\n",
    "dem_path = \"/path/to/filename.vrt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd9ff462-bd67-4611-9dbc-b491ce5a5cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load watersheds data\n",
    "watersheds = geopd.read_file(src_path, layer='attributes_v1')\n",
    "# Deleting sliver polygons\n",
    "watersheds = watersheds[watersheds.area > 100]\n",
    "watersheds = watersheds.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0671bd14-32d6-4df6-8175-a77301b7399c",
   "metadata": {},
   "outputs": [],
   "source": [
    "watersheds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "197b6ec4-7498-44ed-8d01-2e3a8fe9f04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lc_to_watersheds(subwatersheds, land_cover_path, lc_classes, year):\n",
    "    \"\"\"\n",
    "    Adds land cover classification proportions of a spesific year to subwatersheds.\n",
    "\n",
    "    Parameters:\n",
    "    subwatersheds (GeoDataFrame): A GeoDataFrame containing subwatershed geometries and attributes.\n",
    "    land_cover_path (str): Path to the land cover raster file.\n",
    "    lc_classes (dict): A dictionary mapping land cover class values to their names.\n",
    "    year (int): The year of the land cover data.\n",
    "    bounds (tuple): A tuple containing the bounding box coordinates (minx, miny, maxx, maxy).\n",
    "\n",
    "    Returns:\n",
    "    GeoDataFrame: The input GeoDataFrame with additional columns for each land cover class proportion.\n",
    "    \"\"\"\n",
    "    place_id = subwatersheds.at[0, 'Paikka_Id']\n",
    "\n",
    "    for j, subwatershed in subwatersheds.iterrows():\n",
    "\n",
    "        subwatershed = geopd.GeoDataFrame(\n",
    "                dict(zip(list(subwatershed.index), list(subwatershed.values))),\n",
    "                crs=subwatersheds.crs, geometry='geometry', index=[0])\n",
    "\n",
    "        minx = subwatershed.bounds.at[0, 'minx']\n",
    "        miny = subwatershed.bounds.at[0, 'miny']\n",
    "        maxx = subwatershed.bounds.at[0, 'maxx']\n",
    "        maxy = subwatershed.bounds.at[0, 'maxy']\n",
    "\n",
    "        with rasterio.open(land_cover_path) as src:\n",
    "            profile = src.profile\n",
    "            values = src.read(\n",
    "                1, window=from_bounds(minx, miny, maxx, maxy, src.transform),\n",
    "                boundless=True, fill_value=profile['nodata'])\n",
    "        \n",
    "        profile['transform'] = rasterio.transform.from_bounds(minx, miny, maxx, maxy, values.shape[1], values.shape[0])\n",
    "        profile['width'] = values.shape[1]\n",
    "        profile['height'] = values.shape[0]\n",
    "        \n",
    "        area_mask = rasterize(\n",
    "                subwatershed['geometry'], (profile['height'], profile['width']),\n",
    "                dtype=profile['dtype'], transform=profile['transform'], all_touched=True)\n",
    "        \n",
    "        area = area_mask.sum()\n",
    "        \n",
    "        clipped_values = np.where(area_mask == 1, values, 0)\n",
    "        for key in lc_classes:\n",
    "            class_name = lc_classes[key]\n",
    "            class_values = np.where(clipped_values == key, 1, 0)\n",
    "        \n",
    "            class_area = class_values.sum()\n",
    "    \n",
    "            # Some subwaterhseds cause minor problems \n",
    "            warnings.filterwarnings(\"error\")\n",
    "            \n",
    "            try:\n",
    "                class_portion = class_area / area\n",
    "    \n",
    "            except:\n",
    "                class_portion = 0\n",
    "                print(f\"{class_name}_perc was set to zero for watershed {place_id}, subwatershed {j} because {class_area} or {area} were invalid features\")\n",
    "            warnings.filterwarnings(\"default\")\n",
    "            \n",
    "            # Getting percentages\n",
    "            subwatersheds.at[j, f\"{class_name}_perc_{year}\"] = class_portion * 100\n",
    "\n",
    "    return subwatersheds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39674fbd-f993-4710-a70e-c0dc99086898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b28bcf68f8874ee583875d3ef7dc992e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/320 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Main processing loop\n",
    "dst_path = '/path/to/filename.gpkg'\n",
    "pbar = tqdm(watersheds.iterrows(), total=len(watersheds))\n",
    "\n",
    "for i, watershed in pbar:\n",
    "    pbar.set_description(f\"Processing catchment {i}\")\n",
    "    # Changing to GeoDataFrame\n",
    "    watershed = geopd.GeoDataFrame(\n",
    "                    dict(zip(list(watershed.index), list(watershed.values))),\n",
    "                    crs=watersheds.crs, geometry='geometry', index=[0])\n",
    "    \n",
    "    minx = watershed.bounds.at[0, 'minx']\n",
    "    miny = watershed.bounds.at[0, 'miny']\n",
    "    maxx = watershed.bounds.at[0, 'maxx']\n",
    "    maxy = watershed.bounds.at[0, 'maxy']\n",
    "    \n",
    "    \"\"\"\n",
    "    #Land cover\n",
    "    \"\"\"\n",
    "    # Optional progress bar\n",
    "    #pbar.set_description(f\"Doing land cover for catchment {i}\")\n",
    "    year_values = []\n",
    "    counter = 0\n",
    "    for lc_year in land_cover_paths:\n",
    "        land_cover_path = land_cover_paths[lc_year]\n",
    "        watershed = add_lc_to_watersheds(watershed, land_cover_path, lc_classes, lc_year)\n",
    "        # the end result shouldnt have multiple columns with same name and values\n",
    "        #if counter > 0:\n",
    "            #watershed_lc.drop(['geometry', 'area', 'Paikka_Id'], axis=1)\n",
    "        #year_values.append(watershed_lc)\n",
    "        counter += 1\n",
    "    #watershed = pd.concat(year_values, axis=1)\n",
    "    \n",
    "    watersheds.loc[i, lc_columns] = watershed.loc[0, lc_columns]\n",
    "\n",
    "    \"\"\"\n",
    "    #Soil\n",
    "    \"\"\"\n",
    "    #pbar.set_description(f\"Doing soil class for catchment {i}\")\n",
    "    \n",
    "    soil = geopd.read_file(soil_path, bbox=(minx, miny, maxx, maxy))\n",
    "    soil = soil.clip(watershed, keep_geom_type=True)\n",
    "\n",
    "    # There is soil data\n",
    "    if len(soil) > 0:\n",
    "        for soil_class in soil_classes:\n",
    "            # Classifying into given classes\n",
    "            soil.loc[soil[\"PINTAMAALAJI_KOODI\"].isin(soil_classes[soil_class]), \"soil_class\"] = soil_class\n",
    "            \n",
    "        soil = soil.dissolve(by=\"soil_class\", as_index=False)\n",
    "        watershed_area = watershed.area.sum()\n",
    "            \n",
    "        for soil_class in soil_classes:\n",
    "            soil_class_area = soil[soil[\"soil_class\"] == soil_class].area.sum()\n",
    "            # multiplying by 100 to get percentage\n",
    "            watersheds.at[i, f\"{soil_class}_perc\"] = round((soil_class_area / watershed_area) * 100, 4)\n",
    "\n",
    "    # Handling nodata situation\n",
    "    else:\n",
    "        for soil_class in soil_classes:\n",
    "            watersheds.at[i, f\"{soil_class}_perc\"] = 0\n",
    "    \"\"\"\n",
    "    #Soil depth\n",
    "    \"\"\"\n",
    "    #pbar.set_description(f\"Doing soil depth for catchment {i}\")\n",
    "\n",
    "    # Opening window of the data from the area of the watershed    \n",
    "    with rasterio.open(soil_depth_path) as src:\n",
    "        profile = src.profile\n",
    "        values = src.read(\n",
    "            1, window=from_bounds(minx, miny, maxx, maxy, src.transform),\n",
    "            boundless=True, fill_value=profile['nodata'])\n",
    "    \n",
    "    profile['transform'] = rasterio.transform.from_bounds(minx, miny, maxx, maxy, values.shape[1], values.shape[0])\n",
    "    profile['width'] = values.shape[1]\n",
    "    profile['height'] = values.shape[0]\n",
    "\n",
    "    # The typical, non empty case\n",
    "    if profile['width'] and profile['height'] > 0:\n",
    "    \n",
    "        # Nodata and waters are excluded so that they don't interfere\n",
    "        masked_values = ma.masked_values(values, profile['nodata'])\n",
    "        # Waters are represented as -99 and are removed\n",
    "        masked_values = ma.masked_values(masked_values, -99)\n",
    "        \n",
    "        area_mask = rasterize(\n",
    "                    watershed['geometry'], (profile['height'], profile['width']),\n",
    "                    dtype=profile['dtype'], transform=profile['transform'], all_touched=True)\n",
    "    \n",
    "        # When calculating the average, unwanted regions must be masked\n",
    "        clipped_values = ma.masked_where(area_mask == 0, masked_values)\n",
    "        \n",
    "        # If the area is completely covered by lakes, the value is set to 0\n",
    "        warnings.filterwarnings(\"error\") \n",
    "        try:\n",
    "            average_depth = round(clipped_values.sum() / clipped_values.count(), 4)\n",
    "    \n",
    "        except:\n",
    "            average_depth = 0\n",
    "            print(f\"soil depth was set to zero for watershed {i}, because there were no non-masked values\")\n",
    "        warnings.filterwarnings(\"default\") \n",
    "    \n",
    "        watersheds.at[i, f\"soil_depth\"] = average_depth\n",
    "    # Handling the empty exception\n",
    "    else:\n",
    "        print(f\"soil depth was set to zero for watershed {i}, because there were no non-masked values\")\n",
    "        watersheds.at[i, f\"soil_depth\"] = 0\n",
    "\n",
    "    \"\"\"\n",
    "    #Slope\n",
    "    \"\"\"\n",
    "    #pbar.set_description(f\"Doing slope for catchment {i}\")\n",
    "\n",
    "    with rasterio.open(slope_path) as src:\n",
    "            profile = src.profile\n",
    "            values = src.read(\n",
    "                1, window=from_bounds(minx, miny, maxx, maxy, src.transform),\n",
    "                boundless=True, fill_value=profile['nodata'])\n",
    "        \n",
    "    profile['transform'] = rasterio.transform.from_bounds(minx, miny, maxx, maxy, values.shape[1], values.shape[0])\n",
    "    profile['width'] = values.shape[1]\n",
    "    profile['height'] = values.shape[0]\n",
    "\n",
    "    # Nodata and waters are excluded so that they don't interfere\n",
    "    masked_values = ma.masked_values(values, profile['nodata'])\n",
    "\n",
    "    \n",
    "    area_mask = rasterize(\n",
    "            watershed['geometry'], (profile['height'], profile['width']),\n",
    "            dtype=profile['dtype'], transform=profile['transform'], all_touched=True)\n",
    "\n",
    "    # When calculating the average, unwanted regions must be masked\n",
    "    clipped_values = ma.masked_where(area_mask == 0, masked_values)\n",
    "    \n",
    "    # If the area is completely covered by lakes, the value is set to 0\n",
    "    warnings.filterwarnings(\"error\") \n",
    "    try:\n",
    "        average = round(clipped_values.sum() / clipped_values.count(), 4)\n",
    "\n",
    "    except:\n",
    "        average = 0\n",
    "        print(f\"slope was set to zero for watershed {i}, because there were no values\")\n",
    "\n",
    "    warnings.filterwarnings(\"default\") \n",
    "    watersheds.at[i, f\"slope\"] = average\n",
    "\n",
    "    \"\"\"\n",
    "    #Elevation\n",
    "    \"\"\"\n",
    "    \n",
    "    # Opening window of the data from the area of the watershed    \n",
    "    with rasterio.open(dem_path) as src:\n",
    "        profile = src.profile\n",
    "        values = src.read(\n",
    "            1, window=from_bounds(minx, miny, maxx, maxy, src.transform),\n",
    "            boundless=True, fill_value=profile['nodata'])\n",
    "    \n",
    "    profile['transform'] = rasterio.transform.from_bounds(minx, miny, maxx, maxy, values.shape[1], values.shape[0])\n",
    "    profile['width'] = values.shape[1]\n",
    "    profile['height'] = values.shape[0]\n",
    "\n",
    "    # Nodata and waters are excluded so that they don't interfere\n",
    "    masked_values = ma.masked_values(values, profile['nodata'])\n",
    "\n",
    "    \n",
    "    area_mask = rasterize(\n",
    "            watershed['geometry'], (profile['height'], profile['width']),\n",
    "            dtype=profile['dtype'], transform=profile['transform'], all_touched=True)\n",
    "\n",
    "    # When calculating the average, unwanted regions must be masked\n",
    "    clipped_values = ma.masked_where(area_mask == 0, masked_values)\n",
    "    nan_clip_values = clipped_values.filled(np.nan)\n",
    "\n",
    "    \n",
    "    #Calculating elevation descriptors\n",
    "\n",
    "    # Mean\n",
    "    watersheds.at[i, 'elev_mean'] = np.nanmean(nan_clip_values)\n",
    "    # Minimum\n",
    "    watersheds.at[i, 'elev_min'] = clipped_values.min()\n",
    "    \n",
    "    # 10th percentile\n",
    "    watersheds.at[i, 'elev_10'] = np.nanpercentile(nan_clip_values, 10)\n",
    "    # median\n",
    "    watersheds.at[i, 'elev_50'] = np.nanpercentile(nan_clip_values, 50)\n",
    "    # 90 th percentile\n",
    "    watersheds.at[i, 'elev_90'] = np.nanpercentile(nan_clip_values, 90)\n",
    "\n",
    "    #Maximum \n",
    "    watersheds.at[i, 'elev_max'] = clipped_values.max()\n",
    "    \n",
    "    \n",
    "watersheds['elev_range'] =  watersheds['elev_max'] - watersheds['elev_min']\n",
    "watersheds.to_file(dst_path, layer=\"v1\", driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7cf6a65-647d-4e59-910f-84e522a322c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "watersheds.to_file(src_path, layer=\"attributes_v1\", driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7180422-54d0-4983-a1d0-e5e113001502",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "watersheds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
