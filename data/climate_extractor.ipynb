{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b966360-ecc1-4aa0-8f9a-dea87a23676e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import rioxarray as rioxr\n",
    "\n",
    "import geopandas as geopd\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fe65d88-f837-4223-af78-dd9d9bc2fcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the vector watershed file\n",
    "vector_watershed_path = \"/path/to/CAMELS-FI_catchments.gpkg\"\n",
    "watersheds = geopd.read_file(vector_watershed_path, layer='v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62325b5-e0be-43f4-8961-644d0c74d9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the watersheds\n",
    "ax = watersheds.plot(alpha=0.1, color='lightgreen')\n",
    "bounds = ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a1aaed10-6009-4180-a735-f8f8ca805604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_weather(args):\n",
    "    \"\"\" Calculates the daily mean of the given watersheds for one variable, over the time period of one year (and one file)\n",
    "    Does not return anything, instead writes the result to a csv file of shape (timesteps, catchments)\n",
    "    \"\"\"\n",
    "    src_path,  dst_path, watersheds = args\n",
    "\n",
    "    weather = pd.DataFrame(index=pd.to_datetime([]), columns=watersheds.Paikka_Id)\n",
    "    weather.index.name = 'date'\n",
    "\n",
    "    with rioxr.open_rasterio(src_path, mask_and_scale=True) as data_array:\n",
    "        # Iterating over the days in the file \n",
    "        for time_step in data_array.Time:\n",
    "            time = time_step.item()\n",
    "            one_day_data = data_array.sel({'Time':time})\n",
    "\n",
    "            row = []\n",
    "            for i in tqdm(range(len(watersheds))): \n",
    "                watershed = watersheds.iloc[[i]]\n",
    "                place_id = watershed.Paikka_Id[i]\n",
    "                \n",
    "                # Calculating the average of the attribute for the whole catchment\n",
    "                clipped = one_day_data.rio.clip(watershed.geometry.values, crs=watershed.crs)\n",
    "                average = clipped.mean().item()\n",
    "                average = round(average, 1)\n",
    "                \n",
    "                # Failsafe for catchments smaller than the pixel size\n",
    "                if average is np.nan:\n",
    "                    clipped = data_array.rio.clip(watershed.geometry.values, crs=watershed.crs, all_touched=True)\n",
    "                    average = clipped.mean().item()\n",
    "\n",
    "                row.append(average)\n",
    "                \n",
    "            weather.loc[str(time)] = row\n",
    "            \n",
    "    weather.to_csv(dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37396ca6-be00-43ba-b855-18b08d15c974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directories for input and output data\n",
    "root = \"/path/to/finland_climate/fmi_grid\"\n",
    "dst_root = \"/path/to/CAMELS-FI/data/raw_time_series\"\n",
    "\n",
    "# Directories and attributes for climate data\n",
    "dirs = ['RRday', 'ET0_FAO', 'Tday',\n",
    "        'Tgmin', 'Tmin', 'Tmax',\n",
    "        'Rh', 'Globrad', 'Snow']\n",
    "attributes = {'Rh' : 'humidity' ,'ET0_FAO': 'pet', 'Tday': 'temperature_mean',\n",
    "              'Tmin': 'temperature_min', 'Tgmin': 'temperature_gmin', 'Tmax': 'temperature_max',\n",
    "              'RRday': 'precipitation', 'Globrad': 'radiation_global', 'Snow': 'snow_depth'}\n",
    "\n",
    "# Years to process\n",
    "years = (1961, 2023)\n",
    "\n",
    "args = []\n",
    "for current_dir in dirs:\n",
    "    dst_dir =  os.path.join(dst_root, attributes[current_dir])\n",
    "    if not os.path.exists(dst_dir):\n",
    "        os.makedirs(dst_dir)\n",
    "        \n",
    "    for year in range(years[0], years[1] + 1):\n",
    "        if year == 2023 and current_dir == 'Tgmin':\n",
    "            continue\n",
    "        \n",
    "        # Evapotranspiration has differing scheme to all other sources\n",
    "        if current_dir == 'ET0_FAO':\n",
    "            #Pet is only available from 1981\n",
    "            if year < 1981:\n",
    "                continue\n",
    "            # Different time range than other variables\n",
    "            src_file_name = f\"{current_dir}_{year}_months_4_to_9.nc\"\n",
    "        else:\n",
    "            src_file_name = f\"{current_dir.lower()}_{year}.nc\"\n",
    "\n",
    "        src_path = os.path.join(root, current_dir, src_file_name)\n",
    "        if not os.path.exists(src_path):\n",
    "            print(f\"path {src_path} doesn't exist\")\n",
    "            with open(os.path.join(dst_root, \"error_log.txt\"), 'a') as error_log:\n",
    "                error_log.write(f\"Path does not exist:{src_path}\")\n",
    "            continue\n",
    "            \n",
    "        dst_file_name = f\"{attributes[current_dir]}_{year}.csv\"\n",
    "        dst_path = os.path.join(dst_dir, dst_file_name)\n",
    "        args.append((src_path,  dst_path, watersheds))\n",
    "        \n",
    "# Process the data in parallel\n",
    "with Pool() as p:\n",
    "    p.map(mean_weather, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dab116f5-c0a1-4a63-bd3c-3870c84f9b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the mean for a single catchment\n",
    "def catchment_mean(args):\n",
    "    data_array, watershed, time = args\n",
    "    one_day_data = data_array.sel({'Time':time})\n",
    "\n",
    "    # Calculating the average of the attribute for the whole catchment\n",
    "    clipped = one_day_data.rio.clip(watershed.geometry.values, crs=watershed.crs)\n",
    "    average = clipped.mean().item()\n",
    "    average = round(average, 1)\n",
    "    \n",
    "    # Failsafe for catchments smaller than the pixel size\n",
    "    if average is np.nan:\n",
    "        clipped = data_array.rio.clip(watershed.geometry.values, crs=watershed.crs, all_touched=True)\n",
    "        average = clipped.mean().item()\n",
    "        \n",
    "    return average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f834bcf9-3244-4eaa-916d-bb66f28af6e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Process the data for each watershed\n",
    "dst_dir = \"/path/to/CAMELS-FI/data/timeserie\"\n",
    "\n",
    "if not os.path.exists(dst_dir):\n",
    "    os.makedirs(dst_dir)\n",
    "\n",
    "weather = pd.DataFrame(index=pd.to_datetime([]))\n",
    "weather.index.name = 'date'\n",
    "\n",
    "pbar = tqdm(range(len(watersheds)))\n",
    "for i in pbar:\n",
    "    watershed = watersheds.loc[[i]]\n",
    "    place_id = watershed.at[i, 'Paikka_Id']\n",
    "    # Constructing the path of the timeseries for this catchmentparallel \n",
    "    path = os.path.join(dst_dir, f\"CAMELS_FI_hydromet_timeseries_{place_id}_{years[0]}0101-{years[1]}1231.csv\")\n",
    "    for current_dir in dirs:\n",
    "         \n",
    "        for year in range(years[0], years[1] + 1):\n",
    "            pbar.set_description(f\"Processing watershed {place_id:>4}, {attributes[current_dir]:>16}, {year}\")\n",
    "            \n",
    "            # Evapotranspiration has differing scheme to all other sources\n",
    "            if current_dir == 'ET0_FAO':\n",
    "                # Different time range than other variables\n",
    "                file_name = f\"{current_dir}_{year}_months_4_to_9.nc\"\n",
    "            else:\n",
    "                file_name = f\"{current_dir.lower()}_{year}.nc\"\n",
    "                \n",
    "            src_path = os.path.join(root, current_dir, file_name)\n",
    "            if not os.path.exists(src_path):\n",
    "                print(f\"Path {src_path} doesn't exists\")\n",
    "                continue\n",
    "            \n",
    "            with rioxr.open_rasterio(src_path, mask_and_scale=True) as src:\n",
    "                data_array = src.copy()\n",
    "    \n",
    "            # Iterating over the days and adding it to a list for parallel mapping\n",
    "            arg_list = []\n",
    "            times = []\n",
    "            for time_step in data_array.Time:\n",
    "                time = time_step.item()\n",
    "                arg_list.append((data_array, watershed, time))\n",
    "                times.append(str(time))\n",
    "            \n",
    "            with Pool(6) as p:\n",
    "                averages = p.map(catchment_mean, arg_list)\n",
    "            \n",
    "            for average, time in list(zip(averages, times)):\n",
    "                weather.loc[time,  attributes[current_dir]] = average\n",
    "            \n",
    "    weather.to_csv(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
